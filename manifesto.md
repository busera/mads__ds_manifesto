# My Personal Data Science Manifesto

## Core Principles

1. Solve important problems that deliver real value
2. Maintain ethical integrity in all analyses and communications 
3. Embrace uncertainty and communicate it clearly
4. Strive for reproducibility and transparency
5. Continuously learn and improve skills

## Project Phases: Questions, Maxims, and Commitments

### 1. Problem Formulation

#### Essential Questions
- Why is the analysis needed?
- How will the results be used?
- What is the specific target or purpose of the analysis?
- Is the project clearly described and solvable through data analysis?
- What kinds of data would be used?

#### Key Maxims
- The original formulation is rarely the correct formulation.
- Make sure that the problem you are solving is important.
- Challenge the initial business question for clarity and formulation.
- Consider the use scenario and expected value.

#### Ethical Commitment
- Never over-hype what I am going to be able to produce.

### 2. Data Collection & Cleaning

#### Essential Questions
- What is the meaning/description of the provided datasets / columns?
- How was the data sampled?
- Are there any potential biases in the data collection process?
- What are the data quality issues and how can they be addressed?
- Is the sample size sufficient for the analysis?

#### Key Maxims
- Label altered data.
- Be aware of (statistical) bias types during data collection and sampling.
- Only correct values when the data is understood and enough information is gathered.
- Consider creating metadata columns indicating imputed or altered values.
- Document the complete "journey" from raw data to the conclusion.

#### Ethical Commitment
- Be aware of (statistical) bias types during data collection and sampling.
- Never alter results for personal gain.

### 3. Analysis & Modeling

#### Essential Questions
- What are some potential confounders?
- How can we detect and prevent overfitting?
- Are we considering all relevant variables?
- How robust is the model to different assumptions?
- What are the limitations of our analysis?

#### Key Maxims
- Multiple comparisons means more opportunities for false positives.
- Correlation does NOT imply causation.
- A well-functioning ML algorithm will separate the signal from the noise.
- Tell a story about how each feature fits into the model.
- Don't fall for the false cause fallacy or narrative fallacy.

#### Ethical Commitment
- Always verify how the data is used and how results will be interpreted.
- Never hunt or hack for "positive results".
- Avoid p-hacking and HARKing (Hypothesizing After Results are Known).

### 4. Presentation & Deployment

#### Essential Questions
- Is this a situation where we need an explainable model or does a "black box" model also work?
- How can we effectively communicate uncertainty in our results?
- What is the narrative we're building around our insights?
- How can we make our presentation visually appealing and easy to understand?
- What are the potential challenges in deploying this model?

#### Key Maxims
- Present uncertainty in terms of hypothetical concrete outcomes rather than statistical abstractions.
- Don't wait too long to communicate insights, but be careful with sharing premature results.
- Structure presentations using frameworks like SPSN and SUCCESs.
- Use visuals to reinforce key findings and make it easier to follow the storyline.
- Write clean, scalable code and align with engineers early on coding practices.

#### Ethical Commitment
- Always convey the level of uncertainty warranted by my analysis, even if clients don't want to hear about it.
- Work closely with decision-makers to ensure insights are understood and actionable.

## Skills Development Plan

1. Problem Formulation
   - Strengthen ability to conduct effective inquiries leading to good problem formulations
   - Develop a robust repertoire of problem types
   - Improve mapping of domain problems to data science problem types

2. Data Collection & Cleaning
   - Deepen understanding of common data problems leading to misleading results
   - Expand knowledge of potential data sources in application domain
   - Refine techniques for querying, assembling, and cleaning datasets

3. Analysis & Modeling  
   - Master techniques to avoid common modeling mistakes
   - Expand repertoire of models and validation methods
   - Improve ability to interpret results and their implications

4. Presentation & Deployment
   - Enhance storytelling and data visualization skills
   - Develop expertise in presenting to non-technical audiences
   - Improve collaboration with software engineers for model deployment

## Continuous Learning Approach

### Daily
- Follow key data science publications and blogs:
  - Towards Data Science (Medium)
  - Towards AI Team (Medium)

### Weekly
- Listen to data science podcasts:
  - Data Skeptic

### Monthly
- Complete relevant online courses and tutorials:
  - Kaggle courses
  - Coursera specializations
- Engage in hands-on coding practices:
  - DataCamp
  - Kaggle competitions

### Ongoing
- Apply learnings to real-world projects continuously
- Engage regularly with data science community for knowledge sharing
- Stay updated on new tools, best practices, and emerging technologies

By adhering to these principles, continuously developing my skills, and maintaining ethical standards, I commit to delivering high-quality, impactful data science work throughout my career. I will strive to solve important problems, communicate effectively, and always consider the ethical implications of my work.